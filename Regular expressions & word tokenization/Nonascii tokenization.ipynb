{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''In this exercise, you'll practice advanced tokenization by tokenizing some non-ascii based text. You'll be using German with emoji!\n",
    "\n",
    "Here, you have access to a string called german_text, which has been printed for you in the Shell. Notice the emoji and the German characters!\n",
    "\n",
    "The following modules have been pre-imported from nltk.tokenize: regexp_tokenize and word_tokenize.\n",
    "\n",
    "Unicode ranges for emoji are:\n",
    "\n",
    "('\\U0001F300'-'\\U0001F5FF'), ('\\U0001F600-\\U0001F64F'), ('\\U0001F680-\\U0001F6FF'), and ('\\u2600'-\\u26FF-\\u2700-\\u27BF'). ''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''Tokenize all the words in german_text using word_tokenize(), and print the result.\n",
    "Tokenize only the capital words in german_text.\n",
    "First, write a pattern called capital_words to match only capital words. Make sure to check for the German Ü! To use this character in the exercise, copy and paste it from these instructions.\n",
    "Then, tokenize it using regexp_tokenize().\n",
    "Tokenize only the emoji in german_text. The pattern using the unicode ranges for emoji given in the assignment text has been written for you. Your job is to use regexp_tokenize() to tokenize the emoji.\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and print all words in german_text\n",
    "all_words = word_tokenize(german_text)\n",
    "print(all_words)\n",
    "\n",
    "# Tokenize and print only capital words\n",
    "capital_words = r\"[A-ZÜ]\\w+\"\n",
    "print(regexp_tokenize(german_text, capital_words))\n",
    "\n",
    "# Tokenize and print only emoji\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(german_text, emoji))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
